"""
This pipeline runs DLAB-Re and DLAB-VS in succession, producing output scores for them as described
in the paper. Input data needs to be created by data_prep_pipeline.py.
"""
import argparse
import sys
from pathlib import Path

import molgrid
import numpy as np
import pandas as pd
import torch
import yaml

from models.cnn import CNN3D
from models.densenets import densenet_dlab_vs


def get_args():
    """Parse command line args

    Returns:
        argparse.Namespace: parsed command line arguments
    """
    parser = argparse.ArgumentParser()

    parser.add_argument("-c", help="Config yaml file", required=True)
    args = parser.parse_args()

    return args


def parse_yaml(yaml_path: Path):
    """Parses yaml config file

    Args:
        yaml_path (Path): Path to the yaml file

    Returns:
        dict: parsed config
    """

    with open(yaml_path) as yaml_file:
        parsed_yaml = yaml.safe_load(yaml_file)

    return parsed_yaml


def file_len(fname: Path):
    """Return length of file fname (number of lines)

    Args:
        fname (Path): File to be counted.

    Returns:
        int: Number of lines in the file.
    """
    i = 0
    with open(fname) as f:
        for i, l in enumerate(f):
            pass
    return i + 1


def run_dlab_vs(folder: Path, config: dict, dlab_re_df: pd.DataFrame, use_top_n: int, device):
    """Run DLAB-VS as specified by the config file on one complex.

    Args:
        folder (Path): Folder containing the input data in types format
        config (dict): Parsed yaml config
        dlab_re_df (pd.DataFrame): Results from DLAB-Re, generated by run_dlab_re
        use_top_n (int): How many structures to use in the calculation of the DLAB-VS score

    Raises:
        NotImplementedError: If the config specified a model architecture that is not implemented.

    Returns:
        float: The DLAB-VS score for the pairing.
    """

    f_name = folder / "dlab_vs_input.types"

    dlab_re_df.sort_values(by="dlab-re", inplace=True, ascending=False)
    dlab_re_df = dlab_re_df.iloc[:use_top_n]

    # make types file for dlab-vs
    with open(f_name, "w") as outf:
        for row_ind in range(len(dlab_re_df)):
            row = dlab_re_df.iloc[row_ind]
            outf.write(f"1 {row['bp1']} {row['bp2']} #\n")  # format for molgrid parsing

    # to generate the ensemble score, run the models of each architecture specified in the config
    per_model_type_results = []
    for model_type_dict in config["dlab-vs-models"]:
        model_params = model_type_dict["model_params"]
        types_file = folder / "dlab_vs_input.types"

        set_len = use_top_n

        per_net_results = []
        for i in range(
            len(list(Path(model_type_dict["model_directory"]).glob("*.mod")))
        ):
            per_net_results.append(torch.zeros(set_len))

        if set_len < model_params["batch_size"]:
            base_bs = set_len
            num_batches = 1
        elif set_len % model_params["batch_size"] == 0:
            base_bs = model_params["batch_size"]
            num_batches = int(set_len / base_bs)
        else:  # need to have a smaller batch at the end
            num_batches = int(set_len / base_bs) + 1
            base_bs = model_params["batch_size"]

        for net_ind, model_file in enumerate(
            Path(model_type_dict["model_directory"]).glob("*.mod")
        ):
            gmaker, ex_provider = setup_gmaker_eprov(
                model_params["resolution"], model_params["radius"], types_file
            )

            dims = gmaker.grid_dimensions(ex_provider.num_types())
            grid_size = model_params["radius"] * 2 / model_params["resolution"]

            if model_type_dict["model_type"].lower() in ["cnn", "cnn3d"]:
                net = CNN3D(
                    grid_in=grid_size,
                    in_channels=ex_provider.num_types(),
                    out_layer="sigmoid",
                    out_classes=1,
                )
            elif model_type_dict["model_type"].lower() in ["dense", "densenet"]:
                net = densenet_dlab_vs(
                    grid_in=grid_size,
                    in_channels=ex_provider.num_types(),
                    out_layer="sigmoid",
                    out_classes=1,
                )
            else:
                raise NotImplementedError("Net type not implemented")

            net.load_state_dict(torch.load(str(model_file)))
            # device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
            net.to(device)
            net = net.eval()

            with torch.no_grad():
                for i in range(num_batches):
                    if i == (num_batches - 1) and set_len % base_bs != 0:
                        bs = set_len % base_bs
                    else:
                        bs = base_bs

                    tensor_shape = (bs,) + dims
                    batch_tensor = torch.zeros(
                        tensor_shape, dtype=torch.float32
                    ).to(device)

                    batch = ex_provider.next_batch(bs)
                    for j in range(bs):
                        ex = batch[j]
                        gmaker.forward(
                            ex,
                            batch_tensor[j],
                            random_translation=0.0,
                            random_rotation=False,
                            # center=(0.0, 0.0, 0.0),
                        )

                    output = net(batch_tensor)
                    per_net_results[net_ind][
                        (i * base_bs) : ((i * base_bs) + bs)
                    ] = torch.flatten(output)

        per_model_type_results += per_net_results

    arr_list = []
    for t in per_model_type_results:
        arr_list.append(np.array(t))
    ensemble_result = np.mean(np.array(arr_list))  # mean of all models and poses

    return ensemble_result


def setup_gmaker_eprov(resolution: float, radius: float, data_file: Path):
    """Setup the molgrid GridMaker and ExampleProvider for the data specified in data_file.

    Args:
        resolution (float): Resolution of the grid
        radius (float): Radius of the grid in Angstrom
        types_file (Path): File specifying the types file pairings making up the data set

    Returns:
        tuple: GridMaker, ExampleProvider
    """
    # dim is 1 voxel length less than 2xradius to ensure that center is on node between 8 voxels
    gmaker = molgrid.GridMaker(resolution=resolution, dimension=2 * radius - resolution)
    e_provider_test = molgrid.ExampleProvider(
        data_root="", balanced=False, shuffle=False
    )
    e_provider_test.populate(str(data_file))

    return gmaker, e_provider_test


def run_dlab_re(folder: Path, config: dict, device):
    """Run DLAB-Re on the types files in the folder as specified in the config.

    Args:
        folder (Path): folder (Path): Folder containing the input data in gninatypes format
        config (dict): Parsed yaml config

    Raises:
        NotImplementedError: If the config specified a model architecture that is not implemented.

    Returns:
        pd.DataFrame: dataframe containing the DLAB-Re scores for each evaluated pose
    """

    with torch.no_grad():
        per_model_type_results = []
        for model_type_dict in config["dlab-re-models"]:
            model_params = model_type_dict["model_params"]
            types_file = folder / "dlab_re_input.types"
            set_len = file_len(types_file)

            per_net_results = []
            for i in range(
                len(list(Path(model_type_dict["model_directory"]).glob("*.mod")))
            ):
                per_net_results.append(torch.zeros(set_len))

            if set_len % model_params["batch_size"] == 0:
                num_batches = int(set_len / model_params["batch_size"])
            else:  # need to have a smaller batch at the end
                num_batches = int(set_len / model_params["batch_size"]) + 1
            base_bs = model_params["batch_size"]

            for net_ind, model_file in enumerate(
                Path(model_type_dict["model_directory"]).glob("*.mod")
            ):

                gmaker, ex_provider = setup_gmaker_eprov(
                    model_params["resolution"], model_params["radius"], types_file
                )

                # dims = gmaker.grid_dimensions(ex_provider.type_size())
                dims = gmaker.grid_dimensions(ex_provider.num_types())
                tensor_shape = (model_params["batch_size"],) + dims
                batch_tensor = torch.zeros(
                    tensor_shape, dtype=torch.float32
                ).to(device)
                grid_size = model_params["radius"] * 2 / model_params["resolution"]

                if model_type_dict["model_type"].lower() in ["cnn", "cnn3d"]:
                    net = CNN3D(
                        grid_size,
                        # ex_provider.type_size(),
                        ex_provider.num_types(),
                        out_layer="none",
                        out_classes=11,
                    )
                else:
                    raise NotImplementedError("Net option not implemented")

                net.load_state_dict(torch.load(str(model_file)))
                # device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
                net.to(device)
                net = net.eval()

                for i in range(num_batches):
                    if i == (num_batches - 1) and set_len % base_bs != 0:
                        bs = set_len % base_bs
                    else:
                        bs = base_bs

                    batch = ex_provider.next_batch(bs)
                    for j in range(bs):
                        ex = batch[j]
                        gmaker.forward(
                            ex,
                            batch_tensor[j],
                            random_translation=0.0,
                            random_rotation=False,
                            # center=(0.0, 0.0, 0.0),
                        )

                    output = net(batch_tensor)
                    score_tensor = torch.zeros(bs)
                    for row_ind in range(bs):
                        score = 0
                        for j in range(11):
                            score += torch.softmax(output[row_ind], dim=0)[j] * j
                        score_tensor[row_ind] = score
                    per_net_results[net_ind][
                        i * base_bs : (i * base_bs) + bs
                    ] = score_tensor

            per_model_type_results += per_net_results

        arr_list = []
        for t in per_model_type_results:
            arr_list.append(np.array(t))
        ensemble_results = np.mean(np.array(arr_list), axis=0)

        score_df = []
        with open(types_file) as inf:
            lines = inf.readlines()
            for i, l in enumerate(lines):
                name_bp1 = l.split()[2]
                name_bp2 = l.split()[3]
                score = ensemble_results[i]
                score_df.append([name_bp1, name_bp2, score])

    return pd.DataFrame(score_df, columns=["bp1", "bp2", "dlab-re"])


def make_types_file(folder: Path):
    """Generate input file for dlab-re.

    Args:
        folder (Path): Folder in which to generate the file.
    """

    f_name = folder / "dlab_re_input.types"

    with open(f_name, "w") as outf:
        for ab_f in folder.glob("*_ab.gninatypes"):
            ag_f = Path(str(ab_f).replace("_ab.gninatypes", "_ag.gninatypes"))
            if ag_f.exists():
                line = f"1 1.0 {ab_f} {ag_f} #\n"
                outf.write(line)


def get_zdock_score(folder: Path, config: dict):
    """Read out the ZDock score of the highest ranked pose.

    Args:
        folder (Path): Folder name of the DLAB run, used to determine the correct ZDock output file
        config (dict): Parsed yaml config

    Returns:
        float: ZDock score
    """
    docking_path = (
        Path(config["input_directory"]) / "docking_output" / (str(folder.name) + ".out")
    )
    with open(docking_path) as inf:
        lines = inf.readlines()
    score = float(lines[5].split()[-1].strip())
    return score


def run_on_docking_folder(folder: Path, config: dict, device):
    """Run DLAB-Re and DLAB-VS on the output from one ZDock run.

    Args:
        folder (Path): Folder containing the types files generated from the run output
        config (dict): Parsed yaml config

    Returns:
        tuple: dlab-re-max score, dlab-vs score, zdock score
    """
    # run rescoring, get top10, get dlab_re_max value
    make_types_file(folder)
    dlab_re_df = run_dlab_re(folder, config, device)

    # run dlab-vs, get mean score
    dlab_vs_score = run_dlab_vs(folder, config, dlab_re_df, 10, device)

    # get zdock score
    zdock_score = get_zdock_score(folder, config)

    # return folder output
    return (dlab_re_df["dlab-re"].max(), dlab_vs_score, zdock_score)


def run(config: dict, device):
    """Run DLAB on parsed docking output.

    Args:
        config (dict): Parsed config file.
    """
    inputdir_path = Path(config["input_directory"]) / "gninatypes"
    if not inputdir_path.exists():
        raise ValueError("The input directory does not exist.")

    target_dirs = [i for i in inputdir_path.glob("*") if i.is_dir()]

    results = []
    for count, target_dir in enumerate(target_dirs):
        sys.stdout.flush()
        results.append([target_dir.name, run_on_docking_folder(target_dir, config, device)])

    with open(config["output_file"], "w") as outf:
        outf.write("name,dlab-re-max_score,dlab-vs_score,zdock_score\n")
        for result in results:
            name = result[0]
            scores = result[1]
            outf.write(f"{name},{scores[0]},{scores[1]},{scores[2]}\n")


if __name__ == "__main__":
    args = get_args()
    config_dict = parse_yaml(args.c)
    device = 0
    # print(config_dict)
    run(config_dict, device)
